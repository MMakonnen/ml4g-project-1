{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THINGS TO KEEP IN MIND / IMPROVE UPON:\n",
    "\n",
    "major:\n",
    "\n",
    "- for the extra feature engineering part with the histones check whether use correct col for histone peaks and consider incorporating the other extra columns as info as well\n",
    "- check if the column definitons are even correct !!!\n",
    "- keep gene names to make sure that we are not joining the wrong thing!!!\n",
    "- what data is this, asking for referecne \n",
    "- use DNase data, and use histone mark data from H3K4me3 and HЗК27ас since their peak density plots clearly indicate nice normal dist and peaks around the TSS, which indicates that the region is active and ready for transcription\n",
    "\n",
    "- add standarization within cell line before stacking the data (can test different types of standardization)\n",
    "- in end add training with all data but test to pred !!!\n",
    "\n",
    "- for now just stack the data of the two cell lines and train model using combined data with the hope of fitting a model that generalizes beyond cell line\n",
    "-> just stacking the data might not be great\n",
    "- think about trying signal processing tricks to extend features using ML4H libray, on top of self designed features\n",
    "- test simple implementation of CNN (look int literature for what makes sense, see lectures for some general steps) + on top use surrogate spearman correlation loss to train the CNN\n",
    "-> make sure to not give CNN too many par\n",
    "- try getting pairwise loss surrogate for spearman corr to work (but prob have to then go with pytorch), however is approx only and can get quite comp expensive for large datasets due to pairwise comparison\n",
    "- right now use simple setup and dont use all the data that we could be using\n",
    "-> once have det optimal model with optimal hyperpar train on all train & val data and use for final prediction\n",
    "\n",
    "minor:\n",
    "- dropped the gene names, so double check if the gene ordering aligns in the x and y data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     chr  TSS_start  TSS_end gene_name  closest_peak_strength  distance  \\\n",
      "0  chr10      49219    49269     TUBB8               5.178203     24539   \n",
      "1  chr10     135483   135533   ZMYND11               8.986245        32   \n",
      "2  chr10     689618   689668     DIP2C               4.990885    162107   \n",
      "3  chr10     931427   931476    LARP4B              10.234297        64   \n",
      "4  chr10    1005837  1005887    GTPBP4              10.776866     14303   \n",
      "\n",
      "   number_of_peaks  average_peak_strength  \n",
      "0              0.0               0.000000  \n",
      "1              3.0              11.824290  \n",
      "2              0.0               0.000000  \n",
      "3              2.0               8.168684  \n",
      "4              0.0               0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/l4sw2ybd7t3b9gbsrzngsn6w0000gn/T/ipykernel_39413/231959165.py:58: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  result_df['number_of_peaks'].fillna(0, inplace=True)\n",
      "/var/folders/tp/l4sw2ybd7t3b9gbsrzngsn6w0000gn/T/ipykernel_39413/231959165.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  result_df['average_peak_strength'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pybedtools\n",
    "from scripts.gen import tsvLoader, bedLoader\n",
    "\n",
    "# Specify the columns of interest for the TSS data\n",
    "cols_to_use = ['chr', 'TSS_start', 'TSS_end', 'gene_name', 'gene_start', 'gene_end', 'strand']\n",
    "\n",
    "# Load TSS data and histone mark data as BedTool objects\n",
    "tss_x_1_train = tsvLoader(path='data/CAGE-train/X1_train_info.tsv', cols_to_use=cols_to_use)  # Returns BedTool object\n",
    "hist_H3K4me3 = bedLoader(path=\"data/H3K4me3-bed/X1.bed\")  # Returns BedTool object\n",
    "\n",
    "# Step 1: Find the closest peak to each TSS entry\n",
    "# This will add information about the closest peak to each TSS\n",
    "closest_peaks = tss_x_1_train.closest(hist_H3K4me3, d=True)\n",
    "\n",
    "# Step 2: Convert to a pandas DataFrame for further processing\n",
    "df_closest = closest_peaks.to_dataframe(\n",
    "    names=[\n",
    "        'chr', 'TSS_start', 'TSS_end', 'gene_name', 'gene_start', 'gene_end', 'strand',\n",
    "        'peak_chr', 'peak_start', 'peak_end', 'peak_name', 'peak_score', 'peak_strand',\n",
    "        'peak_signal', 'peak_p_value', 'peak_q_value', 'peak_read_count', 'distance'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 3: Calculate the closest peak's strength\n",
    "# The strength can be captured by the 'peak_signal' column, which represents the score/intensity of the closest peak.\n",
    "df_closest['closest_peak_strength'] = df_closest['peak_signal']\n",
    "\n",
    "# Step 4: Count the number of peaks within a 2kb window around each TSS\n",
    "# Use `window` to find peaks within 2kb (2000 bases) of each TSS\n",
    "window_peaks = tss_x_1_train.window(hist_H3K4me3, w=2000)\n",
    "\n",
    "# Convert the window results into a DataFrame\n",
    "df_window = window_peaks.to_dataframe(\n",
    "    names=[\n",
    "        'chr', 'TSS_start', 'TSS_end', 'gene_name', 'gene_start', 'gene_end', 'strand',\n",
    "        'peak_chr', 'peak_start', 'peak_end', 'peak_name', 'peak_score', 'peak_strand',\n",
    "        'peak_signal', 'peak_p_value', 'peak_q_value', 'peak_read_count'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 5: Aggregate the number of peaks and the average peak strength for each TSS within the window\n",
    "# Group by TSS and calculate count and mean of 'peak_signal'\n",
    "peak_summary = df_window.groupby(['chr', 'TSS_start', 'TSS_end', 'gene_name']).agg(\n",
    "    number_of_peaks=('peak_signal', 'count'),\n",
    "    average_peak_strength=('peak_signal', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Merge the closest peak information with the summary data from the window operation\n",
    "result_df = pd.merge(\n",
    "    df_closest[['chr', 'TSS_start', 'TSS_end', 'gene_name', 'closest_peak_strength', 'distance']],\n",
    "    peak_summary,\n",
    "    on=['chr', 'TSS_start', 'TSS_end', 'gene_name'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values for TSS entries with no nearby peaks (e.g., for average peak strength)\n",
    "result_df['number_of_peaks'].fillna(0, inplace=True)\n",
    "result_df['average_peak_strength'].fillna(0, inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame with the new features\n",
    "print(result_df.head())\n",
    "\n",
    "# Save the extended TSS data with the new features (optional)\n",
    "result_df.to_csv('data/CAGE-train/X1_train_info_extended.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>TSS_start</th>\n",
       "      <th>TSS_end</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>closest_peak_strength</th>\n",
       "      <th>distance</th>\n",
       "      <th>number_of_peaks</th>\n",
       "      <th>average_peak_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr10</td>\n",
       "      <td>49219</td>\n",
       "      <td>49269</td>\n",
       "      <td>TUBB8</td>\n",
       "      <td>5.178203</td>\n",
       "      <td>24539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr10</td>\n",
       "      <td>135483</td>\n",
       "      <td>135533</td>\n",
       "      <td>ZMYND11</td>\n",
       "      <td>8.986245</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.824290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr10</td>\n",
       "      <td>689618</td>\n",
       "      <td>689668</td>\n",
       "      <td>DIP2C</td>\n",
       "      <td>4.990885</td>\n",
       "      <td>162107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr10</td>\n",
       "      <td>931427</td>\n",
       "      <td>931476</td>\n",
       "      <td>LARP4B</td>\n",
       "      <td>10.234297</td>\n",
       "      <td>64</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.168684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr10</td>\n",
       "      <td>1005837</td>\n",
       "      <td>1005887</td>\n",
       "      <td>GTPBP4</td>\n",
       "      <td>10.776866</td>\n",
       "      <td>14303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14305</th>\n",
       "      <td>chr9</td>\n",
       "      <td>137575166</td>\n",
       "      <td>137575216</td>\n",
       "      <td>DPH7</td>\n",
       "      <td>2.578880</td>\n",
       "      <td>63</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.372441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14306</th>\n",
       "      <td>chr9</td>\n",
       "      <td>137590440</td>\n",
       "      <td>137590490</td>\n",
       "      <td>ZMYND19</td>\n",
       "      <td>19.090852</td>\n",
       "      <td>190</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.529227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14307</th>\n",
       "      <td>chr9</td>\n",
       "      <td>137614164</td>\n",
       "      <td>137614214</td>\n",
       "      <td>ARRDC1</td>\n",
       "      <td>17.730647</td>\n",
       "      <td>3213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14308</th>\n",
       "      <td>chr9</td>\n",
       "      <td>137618991</td>\n",
       "      <td>137619041</td>\n",
       "      <td>EHMT1</td>\n",
       "      <td>17.730647</td>\n",
       "      <td>107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.347564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14309</th>\n",
       "      <td>chr9</td>\n",
       "      <td>137877788</td>\n",
       "      <td>137877838</td>\n",
       "      <td>CACNA1B</td>\n",
       "      <td>4.497391</td>\n",
       "      <td>119385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14310 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         chr  TSS_start    TSS_end gene_name  closest_peak_strength  distance  \\\n",
       "0      chr10      49219      49269     TUBB8               5.178203     24539   \n",
       "1      chr10     135483     135533   ZMYND11               8.986245        32   \n",
       "2      chr10     689618     689668     DIP2C               4.990885    162107   \n",
       "3      chr10     931427     931476    LARP4B              10.234297        64   \n",
       "4      chr10    1005837    1005887    GTPBP4              10.776866     14303   \n",
       "...      ...        ...        ...       ...                    ...       ...   \n",
       "14305   chr9  137575166  137575216      DPH7               2.578880        63   \n",
       "14306   chr9  137590440  137590490   ZMYND19              19.090852       190   \n",
       "14307   chr9  137614164  137614214    ARRDC1              17.730647      3213   \n",
       "14308   chr9  137618991  137619041     EHMT1              17.730647       107   \n",
       "14309   chr9  137877788  137877838   CACNA1B               4.497391    119385   \n",
       "\n",
       "       number_of_peaks  average_peak_strength  \n",
       "0                  0.0               0.000000  \n",
       "1                  3.0              11.824290  \n",
       "2                  0.0               0.000000  \n",
       "3                  2.0               8.168684  \n",
       "4                  0.0               0.000000  \n",
       "...                ...                    ...  \n",
       "14305              2.0               9.372441  \n",
       "14306              2.0              17.529227  \n",
       "14307              0.0               0.000000  \n",
       "14308              2.0              17.347564  \n",
       "14309              0.0               0.000000  \n",
       "\n",
       "[14310 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions used\n",
    "\n",
    "\n",
    "# extends cell line data with simple features\n",
    "def extend_df(df, col_to_keep):\n",
    "    # Add a binary column for strand\n",
    "    df['strand_binary'] = df['strand'].map({'+': 1, '-': 0})\n",
    "    \n",
    "    # gene length\n",
    "    df['gene_length'] = df['gene_end'] - df['gene_start']\n",
    "    \n",
    "    # transcription site length\n",
    "    df['trans_site_len'] = df['TSS_end'] - df['TSS_start']\n",
    "    \n",
    "    # ratio transcription site length & land gene length\n",
    "    df['trans_gene_ratio'] = df['trans_site_len'] / df['gene_length']\n",
    "    \n",
    "    return df[col_to_keep]\n",
    "\n",
    "\n",
    "\n",
    "# NOT BEING USED !!!!\n",
    "# Custom surrogate loss function for Spearman correlation (Pairwise loss)\n",
    "def pairwise_loss(y_true, y_pred):\n",
    "    # Convert predicted values to a 1D numpy array\n",
    "    y_pred = y_pred.ravel()\n",
    "    \n",
    "    # Calculate the pairwise differences for predicted values\n",
    "    pred_diff = np.expand_dims(y_pred, axis=1) - np.expand_dims(y_pred, axis=0)\n",
    "    \n",
    "    # Calculate the pairwise differences for true values\n",
    "    true_diff = np.expand_dims(y_true, axis=1) - np.expand_dims(y_true, axis=0)\n",
    "    \n",
    "    # Sigmoid of the differences (this creates a smooth approximation for ranking)\n",
    "    sigmoid_pred_diff = 1 / (1 + np.exp(-pred_diff))\n",
    "    \n",
    "    # Compute the gradient as the difference between the predictions and the true order\n",
    "    grad = sigmoid_pred_diff - (true_diff > 0).astype(np.float32)\n",
    "    \n",
    "    # The Hessian is a constant in pairwise loss (can be set to a fixed value)\n",
    "    hess = np.ones_like(grad)\n",
    "    \n",
    "    return grad.ravel(), hess.ravel()\n",
    "\n",
    "\n",
    "# Custom evaluation metric for Spearman correlation\n",
    "# -> used as eval metric during training ()\n",
    "def spearman_correlation(preds, train_data):\n",
    "    y_true = train_data.get_label()\n",
    "    corr, _ = spearmanr(y_true, preds)\n",
    "    return 'spearman', corr, True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "\n",
    "# reproducibility seed\n",
    "seed = 42\n",
    "\n",
    "hpo_size = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "\n",
    "# load cell line data (x/y for feature/target, 1/2/3 for cell line and train/val/test indicating assignment)\n",
    "\n",
    "# features \n",
    "x_1_train = pd.read_csv('data/CAGE-train/X1_train_info.tsv', sep='\\t')\n",
    "x_1_val = pd.read_csv('data/CAGE-train/X1_val_info.tsv', sep='\\t')\n",
    "x_2_train = pd.read_csv('data/CAGE-train/X2_train_info.tsv', sep='\\t')\n",
    "x_2_val = pd.read_csv('data/CAGE-train/X2_val_info.tsv', sep='\\t')\n",
    "\n",
    "x_3_test = pd.read_csv('data/CAGE-train/X3_test_info.tsv', sep='\\t')\n",
    "\n",
    "# targets\n",
    "y_1_train = pd.read_csv('data/CAGE-train/X1_train_y.tsv', sep='\\t')\n",
    "y_1_val = pd.read_csv('data/CAGE-train/X1_val_y.tsv', sep='\\t')\n",
    "y_2_train = pd.read_csv('data/CAGE-train/X2_train_y.tsv', sep='\\t')\n",
    "y_2_val = pd.read_csv('data/CAGE-train/X2_val_y.tsv', sep='\\t')\n",
    "\n",
    "\n",
    "# save gene order (might be relevant down the line)\n",
    "genes_1_train = x_1_train['gene_name']\n",
    "genes_1_val = x_1_val['gene_name']\n",
    "genes_2_train = x_2_train['gene_name']\n",
    "genes_2_val = x_2_val['gene_name']\n",
    "genes_3_test = x_3_test['gene_name']\n",
    "\n",
    "\n",
    "# features to use for prediction\n",
    "pred_feat = ['strand_binary', 'gene_length', 'trans_site_len', 'trans_gene_ratio']\n",
    "\n",
    "''' \n",
    "1) To find the optimal model and hyperparameters we use the train data (split for training and hyperparoptim)\n",
    "2) Once we have found the optimal model we get an estimate for the test set error on the validation data\n",
    "3) Before submission we train the best model (model + hyperpar) on the train and validation data and then predict test for submission\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing & feature engineering\n",
    "\n",
    "# ...\n",
    "x_1_train = extend_df(x_1_train, pred_feat)\n",
    "x_1_val = extend_df(x_1_val, pred_feat)\n",
    "x_2_train = extend_df(x_2_train, pred_feat)\n",
    "x_2_val = extend_df(x_2_val, pred_feat)\n",
    "\n",
    "x_3_test = extend_df(x_3_test, pred_feat)\n",
    "\n",
    "\n",
    "# drop gene name from y\n",
    "y_1_train = y_1_train.drop('gene_name', axis=1)\n",
    "y_1_val = y_1_val.drop('gene_name', axis=1)\n",
    "y_2_train = y_2_train.drop('gene_name', axis=1)\n",
    "y_2_val = y_2_val.drop('gene_name', axis=1)\n",
    "\n",
    "\n",
    "# stack features of cell line 1 and 2 (STARTING POINT, CAN TEST SOMETHING ELSE TO IMPROVE UPON THIS)\n",
    "# CAREFUL, remember stacking order for gene names if necessary!!!\n",
    "\n",
    "# x\n",
    "x_1_2_train = pd.concat([x_1_train, x_2_train], ignore_index=True)\n",
    "x_1_2_val = pd.concat([x_1_val, x_2_val], ignore_index=True)\n",
    "# y\n",
    "y_1_2_train = pd.concat([y_1_train, y_2_train], ignore_index=True)\n",
    "y_1_2_val = pd.concat([y_1_val, y_2_val], ignore_index=True)\n",
    "\n",
    "\n",
    "# split train data into data for training and hyperparoptim\n",
    "x_1_2_train_only, x_1_2_train_hpo, y_1_2_train_only, y_1_2_train_hpo = train_test_split(x_1_2_train, y_1_2_train, test_size=hpo_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to train LightGBM model\n",
    "x_y_1_2_train_only = lgb.Dataset(x_1_2_train_only, label=y_1_2_train_only)\n",
    "\n",
    "# Parameters for LightGBM with Huber loss\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'huber',\n",
    "    'alpha': 0.9,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 40,\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "# train model\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    x_y_1_2_train_only,\n",
    ")\n",
    "\n",
    "# eval model for hyperparoptim\n",
    "y_pred_hpo = model.predict(x_1_2_train_hpo)\n",
    "\n",
    "# Calculate Spearman correlation for the predictions\n",
    "spearman_corr, _ = spearmanr(y_1_2_train_hpo, y_pred_hpo)\n",
    "print(f'Spearman correlation on validation set (x_y_1_2_train_hpo): {spearman_corr}')\n",
    "# -> use this for hyperparoptim\n",
    "\n",
    "# FINAL ESTIMATE TEST SET ERROR ... (use val data, but in end use test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.1 - Modeling Choices & Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Load your feature (bed and/or bigwig and/or fasta) and target files (tsv) here.\n",
    "# Decide which features to use for training. Feel free to process them however you need.\n",
    "\n",
    "# NOTE: \n",
    "# bed and bigwig files contain signals of all chromosomes (including sex chromosomes).\n",
    "# Training and validation split based on chromosomes has been done for you. \n",
    "# However, you can resplit the data in any way you want.\n",
    "\n",
    "path_data = \"/path/to/your/data/files\"  # TODO\n",
    "path_test = \"/path/to/test/info/file\"   # X3_test_info.tsv ; TODO\n",
    "test_genes = pd.read_csv(path_test, sep='\\t')\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.2 - Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Select the best model to predict gene expression from the obtained features in WP 1.1.\n",
    "\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.3 - Prediction on Test Data (Evaluation Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Using the model trained in WP 1.2, make predictions on the test data (chr 1 of cell line X3).\n",
    "# Store predictions in a variable called \"pred\" which is a numpy array.\n",
    "\n",
    "pred = None\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Check if \"pred\" meets the specified constrains\n",
    "assert isinstance(pred, np.ndarray), 'Prediction array must be a numpy array'\n",
    "assert np.issubdtype(pred.dtype, np.number), 'Prediction array must be numeric'\n",
    "assert pred.shape[0] == len(test_genes), 'Each gene should have a unique predicted expression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Predictions in the Required Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions in a ZIP. \n",
    "# Upload this zip on the project website under \"Your submission\".\n",
    "# Zip this notebook along with the conda environment (and README, optional) and upload this under \"Your code\".\n",
    "\n",
    "save_dir = 'path/to/save/output/file'  # TODO\n",
    "file_name = 'gex_predicted.csv'         # PLEASE DO NOT CHANGE THIS\n",
    "zip_name = \"LastName_FirstName_Project1.zip\" # TODO\n",
    "save_path = f'{save_dir}/{zip_name}'\n",
    "compression_options = dict(method=\"zip\", archive_name=file_name)\n",
    "\n",
    "test_genes['gex_predicted'] = pred.tolist()\n",
    "test_genes[['gene_name', 'gex_predicted']].to_csv(save_path, compression=compression_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g-proj-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
